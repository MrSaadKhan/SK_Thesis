nohup: ignoring input
2024-08-31 22:24:10.429702: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-08-31 22:24:10.594327: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-08-31 22:24:11.532580: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-31 22:24:13.152151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Creating embeddings at vector size: 128
['nature_remo.json', 'xiaomi_mijia_led.json', 'irobot_roomba.json', 'planex_smacam_pantilt.json', 'jvc_kenwood_hdtv_ip_camera.json']
Traceback (most recent call last):
  File "1-main_create_all_embeddings.py", line 158, in <module>
    times, memories = main(device_low, device_high, save_dir, data_path, vector)
  File "/home/iotresearch/saad/FastTextExp/venv/lib/python3.8/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/iotresearch/saad/FastTextExp/venv/lib/python3.8/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "1-main_create_all_embeddings.py", line 39, in main
    model_filename = create_fasttext_embeddings.train_fasttext_model(file_path, device_list, new_dir, data_path, 1, vector_size)
  File "/home/iotresearch/saad/FastTextExp/thesis_b/create_fasttext_embeddings.py", line 33, in train_fasttext_model
    seen, _ = get_data.get_seen_data(data_path, device)
ValueError: too many values to unpack (expected 2)
